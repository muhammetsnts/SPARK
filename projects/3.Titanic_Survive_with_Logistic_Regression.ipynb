{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.Titanic_Survive_with_Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNlAaBw8OQKRdzI0NJMkYym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammetsnts/SPARK/blob/main/projects/3.Titanic_Survive_with_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOs5LuxNuJo1"
      },
      "source": [
        "# Project Info\n",
        "\n",
        "We will try to predict the passengers will survive or not by using `titanic.csv` dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7yCNL4iR5x3"
      },
      "source": [
        "# Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZZ4nklL2ja4"
      },
      "source": [
        "# install Java8\n",
        "!apt-get -q install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# download spark3.1.1\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "\n",
        "# unzip it\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "\n",
        "# install findspark \n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "#spark = SparkSession.builder.appName('lr').getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs0g_rEaSAE9"
      },
      "source": [
        "# Download and Read Dataset\n",
        "We will use the titanic dataset for classification example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfKWSW-06LEW"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/muhammetsnts/SPARK/main/data/titanic.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO3HeuacQ-yE"
      },
      "source": [
        "data = spark.read.csv(\"titanic.csv\", inferSchema=True, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8l1em4sR1bE",
        "outputId": "b7293e9e-3648-4cbc-9fa3-7f0007a957ac"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
            "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
            "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
            "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
            "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
            "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
            "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
            "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
            "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
            "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
            "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4i8asDhdL4B",
        "outputId": "a8f7f9ca-7d01-44be-eac7-cf85823da09c"
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb0Y551udw7H"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqNlUhVIdnSy",
        "outputId": "ba8f277f-4b65-495a-a43f-a976e5ec788a"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PassengerId',\n",
              " 'Survived',\n",
              " 'Pclass',\n",
              " 'Name',\n",
              " 'Sex',\n",
              " 'Age',\n",
              " 'SibSp',\n",
              " 'Parch',\n",
              " 'Ticket',\n",
              " 'Fare',\n",
              " 'Cabin',\n",
              " 'Embarked']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjHwkPAFd2sv"
      },
      "source": [
        "We will select the columns that will use only.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWpJzymPd1k3"
      },
      "source": [
        "my_cols = data.select(['Survived',\n",
        "                       'Pclass', \n",
        "                       'Sex',\n",
        "                       'Age',\n",
        "                       'SibSp',\n",
        "                       'Parch',\n",
        "                       'Fare',\n",
        "                       'Embarked'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InqzuY4Rea0S"
      },
      "source": [
        "## Dealing with Missing Data\n",
        "\n",
        "We will just drop all missing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02wtdTC6eYCb"
      },
      "source": [
        "final_data = my_cols.na.drop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhPK3_-te1ke"
      },
      "source": [
        "## Dealing with Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFQialHKejIW"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler, VectorIndexer, OneHotEncoder, StringIndexer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R5VVaBQiUuC"
      },
      "source": [
        "### STRING INDEXER\n",
        "\n",
        "Allows us to convert every string into number. Example:\n",
        "\n",
        "|A| B| C|\n",
        "|-|-|-|\n",
        "|0|1|2|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEq5SBmGi4b5"
      },
      "source": [
        "### ONEHOT ENCODER\n",
        "Transforms the indexed numbers into vector format. Example:\n",
        "\n",
        "KEY: A B C\n",
        "\n",
        "For A:\n",
        "[1, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LywVVi_igv97"
      },
      "source": [
        "gender_indexer = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
        "gender_encoder = OneHotEncoder(inputCol='SexIndex', outputCol='SexVec')\n",
        "\n",
        "embark_indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkIndex')\n",
        "embark_encoder = OneHotEncoder(inputCol='EmbarkIndex', outputCol='EmbarkVec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAIePtzXjfq0"
      },
      "source": [
        "assembler = VectorAssembler(inputCols=['Pclass', 'SexVec', 'EmbarkVec', 'Age', 'SibSp', 'Parch', 'Fare'], \n",
        "                            outputCol='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeXH5-FOkJNY"
      },
      "source": [
        "# Logistic Regression Model with Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kGi0haJj5vi"
      },
      "source": [
        "We have created indexers but we need to call them. So we will use `Pipeline` approach before creating the classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nxe4u2ej2Su"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tCtin5EkSvN"
      },
      "source": [
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIjYKpz4kbqU"
      },
      "source": [
        "log_reg_titanic = LogisticRegression(featuresCol='features', labelCol='Survived')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FnKMDH9lBFi"
      },
      "source": [
        "pipeline = Pipeline(stages=[\n",
        "                            gender_indexer,\n",
        "                            gender_encoder,\n",
        "                            embark_indexer,\n",
        "                            embark_encoder,\n",
        "                            assembler,\n",
        "                            log_reg_titanic\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwcorkMDlWni"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oBh2kAFlUmy"
      },
      "source": [
        "train_data, test_data = final_data.randomSplit([0.7,0.3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50kjt6JQlo3f"
      },
      "source": [
        "## Fitting Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaBCMS9cllhh"
      },
      "source": [
        "fit_model = pipeline.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ8vCafAl9yQ"
      },
      "source": [
        "## Transform Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEEc0zUYlwBI"
      },
      "source": [
        "results = fit_model.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Wn9AQymFvu"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-J3SYKRmUlG",
        "outputId": "97df02c4-5d2d-406c-9ae7-f98ccd7a13c8"
      },
      "source": [
        "results.select('Survived','prediction').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+----------+\n",
            "|Survived|prediction|\n",
            "+--------+----------+\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       1.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       0.0|\n",
            "|       0|       1.0|\n",
            "|       0|       0.0|\n",
            "+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK7555JemE-Q"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5rJ-ncEmKqH"
      },
      "source": [
        "# BinaryClassificationEvaluator will return the are under the ROC\n",
        "\n",
        "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Survived')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvfWc4s1mcGK"
      },
      "source": [
        "AUC = my_eval.evaluate(results) # Area Under the Curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4LOjo04mslG",
        "outputId": "ec157f88-a4da-42a2-f082-c1a6dbe796e0"
      },
      "source": [
        "AUC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7859375"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}